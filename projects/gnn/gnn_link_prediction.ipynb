{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# GNNs for Automated Feature Engineering"],"metadata":{"id":"JpiTHcCoQWKB"}},{"cell_type":"markdown","source":["## Manual Feature Engineering"],"metadata":{"id":"E3tPOU5CV8rS"}},{"cell_type":"markdown","source":["Feature engineering is a pivotal process in machine learning, *involving the selection, creation, and transformation of input variables* to enhance model performance. It entails tasks such as feature selection to identify essential variables, creating new features to capture complex relationships, and handling data preprocessing tasks like encoding categorical variables or scaling values. *This process heavily relies on domain expertise and evolves over time to adapt to changing data dynamics, ultimately ensuring that machine learning models are equipped with the most relevant and informative features for accurate predictions and insights.*\n","\n","**In the Mini Project on Graph ML, we performed manual feature engineering on the Stanford Facebook Dataset for clustering Graph nodes**"],"metadata":{"id":"EVBi0zrQWE1X"}},{"cell_type":"markdown","source":["## Automated Feature Engineering through Supervised Neural Networks"],"metadata":{"id":"T06fRF0mWsIR"}},{"cell_type":"markdown","source":["Neural networks excel not only in learning complex patterns but also in automating feature engineering. Rather than manually designing features, neural networks can process raw data and derive informative representations automatically. For instance, in image classification, Convolutional Neural Networks (CNNs) can learn essential image features such as edges, textures, and shapes directly from pixel values. Similarly, Recurrent Neural Networks (RNNs) are proficient at capturing sequential patterns, making them suitable for natural language processing tasks where they can extract meaningful features from text data. Neural networks, with their ability to discover intricate relationships and abstractions within data, have revolutionized feature engineering by streamlining the process and achieving state-of-the-art results across various domains.\n","\n","**One common methodology for feature extraction using neural networks involves training a Neural Network Classifier on a labeled dataset, feeding the raw data into the trained classifier, and utilizing the outputs from intermediate layers as the extracted features. This approach formulates the problem as a supervised classification task.**\n","\n","This process is reminiscent of the **AutoEncoder** architecture for Feature Extraction. *However, in cases where labeled data is not available, as was the situation with the AutoEncoder, the output remains the same as the input, and during training, the model learns useful representations of the input data that can be considered as extracted features.*"],"metadata":{"id":"4O0T1kIIWvJd"}},{"cell_type":"markdown","source":["## Graph Neural Networks for Automated Feature Engineering on Graph Data"],"metadata":{"id":"Z0jeCJ_fW7AK"}},{"cell_type":"markdown","source":["Graph Neural Networks (GNNs) have emerged as a powerful tool for feature extraction in various domains, particularly where data is structured as graphs. GNNs excel in capturing complex relationships and patterns within graph-structured data, making them valuable for tasks like recommendation systems, social network analysis, and molecule property prediction. Instead of relying on manually crafted features, GNNs learn feature representations directly from the graph structure and node attributes. They propagate information between connected nodes through multiple layers, iteratively refining node embeddings.\n","\n","**In this exercise, we will learn how to use a GNN for extracting node features, and later use the engineered node features for clustering, just like in the Mini ML Project.**"],"metadata":{"id":"xh0IC7sMXIbP"}},{"cell_type":"markdown","source":["*This notebook is designed to help you guide how to approach this assignment.*\n","\n","<i><font color='blue'>Some parts of the notebook are left as exercise for you and are the corresponding headers are marked in blue</font></i>"],"metadata":{"id":"I4boAmFpapAX"}},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"CKzeLGIEXfRH"}},{"cell_type":"markdown","source":["We will use the same \"Stanford Facebook\" Dataset as used in the Mini ML Project. The Dataset contains links between several nodes (users) in a Social Network."],"metadata":{"id":"4C44JcK0Xkkd"}},{"cell_type":"markdown","source":["## Install and Importing the required libraries"],"metadata":{"id":"p65riq5ibI29"}},{"cell_type":"code","source":["!pip3 install torch_geometric igraph"],"metadata":{"id":"Ulpnp78BCRry"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","from torch_geometric.utils import from_networkx\n","import torch\n","import numpy as np\n","import torch_geometric.transforms as T\n","import networkx as nx\n","\n","from sklearn.metrics import roc_auc_score\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.utils import negative_sampling"],"metadata":{"id":"ycFJLDcKXjPM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Mount Google Drive, and download the dataset"],"metadata":{"id":"vnR5YJP5bYu9"}},{"cell_type":"code","source":["drive.mount('/content/gdrive', force_remount=True)"],"metadata":{"id":"DwUKHCGQbe76"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget -P /content/gdrive/MyDrive/gnn-data  https://snap.stanford.edu/data/facebook_combined.txt.gz\n","!cd /content/gdrive/MyDrive/gnn-data && gunzip facebook_combined.txt.gz"],"metadata":{"id":"3m2yR0pfCL_9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Let's construct the Graph using the connections (Edge) list in the dataset"],"metadata":{"id":"4iX2v-azdvQK"}},{"cell_type":"markdown","source":["<font color='blue'>Write code to load the dataset from the txt file. Your code should finally return a torch_geometric Data Object</font>"],"metadata":{"id":"GavxgNKjEyZt"}},{"cell_type":"code","source":["# read the dataset from the txt file\n","# return the data as a torch_geomtric data object"],"metadata":{"id":"dcwsEkBzl6mk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The Dataset contains no node features. It only contains a list of connections/edge between various nodes, denoting a real connection in the social network.\n","\n","But a GNN, just like any other Neural Network, needs some encoded inputs to work on.\n","\n","Let's utilize node adjacency information as input features to the GNN."],"metadata":{"id":"NaFom3kfefv3"}},{"cell_type":"markdown","source":["<font color='blue'>Write code to generate adjacency matrix on the graph</font>"],"metadata":{"id":"n5gKnVgtFjwC"}},{"cell_type":"code","source":["# create adjacency matrix\n","# check its shape"],"metadata":{"id":"BcSxnoXx0-wU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now adding these features to the graph"],"metadata":{"id":"yMqK_zFFn6Qk"}},{"cell_type":"code","source":["data.x = torch.tensor(adj_matrix.toarray(), dtype=torch.float32)"],"metadata":{"id":"LNHsy7tjvUpz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.x"],"metadata":{"id":"yhWyw2m8z_rD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Learning Node Embeddings through a Supervised GNN"],"metadata":{"id":"5eeQBWL0o5LY"}},{"cell_type":"markdown","source":["**Objective of Node Embeddings:**\n","\n","The primary goal of node embeddings is to represent nodes features (adjacency information) in a lower-dimensional space where similar nodes in the original graph are closer to each other in the embedding space, and dissimilar nodes are farther apart. This representation should capture the structural and relational information present in the graph.\n","\n","**Detecting Edge Presence:**\n","\n","One way to evaluate the quality of node embeddings and how well they capture relationships is by assessing their ability to predict the presence or absence of edges in the original graph.\n","If an edge exists between two nodes in the original graph, it's expected that their corresponding embeddings in the lower-dimensional space should be close to each other or have a high similarity.\n","Conversely, if there is no edge between two nodes in the original graph, their embeddings should be relatively farther apart or have a lower similarity.\n","\n","**Edge Presence in Embedding Space:**\n","\n","The presence of an edge in the graph obtained from the node embeddings can be an indicator of how well the embeddings capture the original graph's structure. If the embeddings are effective, you would expect edges to exist in the embedding-based graph for node pairs with strong structural relationships in the original graph."],"metadata":{"id":"ptNPXid-4HHk"}},{"cell_type":"markdown","source":["<u>Therefore, we will formulate this problem as a link prediction problem</u>.\n","\n","We will use the adjacency features we just created, in order to train a GNN which would predicts links between the input nodes."],"metadata":{"id":"qKv3J_Fv5nuN"}},{"cell_type":"markdown","source":["## Encoder-Decoder Architecture for Link Prediction"],"metadata":{"id":"FGv8s8-g5_oT"}},{"cell_type":"markdown","source":["An Encoder-Decoder based GNN is often used for Link Prediction problem.\n","\n","In the context of edge detection or link prediction, you want to determine whether there should be an edge (connection) between two nodes or not.\n","\n","The encoder-decoder architecture can be used to achieve this by using the learned node embeddings:\n","\n","Encoder: The encoder part of the model takes the graph structure and node embeddings as input and encodes this information into meaningful node representations in the embedding space. This encoding step captures the similarity between nodes based on their embeddings.\n","\n","Decoder: The decoder takes pairs of node embeddings (corresponding to two nodes in the graph) as input and produces a prediction of whether there should be an edge between those nodes or not. This prediction is based on the similarity captured in the embeddings.\n","\n","Refer to example here for reference: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/link_pred.py . Notice the usage of an encoder-decoder architecture."],"metadata":{"id":"nRMtfl666Son"}},{"cell_type":"markdown","source":["<font color='blue'>Write code to split the Graph into Train, Validation and Test using T.Compose</font>"],"metadata":{"id":"fr6UyrzL6g0M"}},{"cell_type":"code","source":["# use T.Compose transform to split into train, val and test data"],"metadata":{"id":"pH2fU0YuNNc5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### The GNN"],"metadata":{"id":"Mq-1Cndz65aB"}},{"cell_type":"markdown","source":["<font color='blue'>Write the GNN for Link Prediction. </font>\n","\n","Refer to the following example from torch_geomtric:\n","https://github.com/pyg-team/pytorch_geometric/blob/master/examples/link_pred.py"],"metadata":{"id":"gFx9DotN67pv"}},{"cell_type":"code","source":["# write GNN code here"],"metadata":{"id":"Dryv_4x-eOBw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color='blue'> Now write code to train the model. Experiment with various hyperparameters such as output dimensions, number of epochs etc. Also experiment with different model architectures but increasing or decreasing the number of hidden layers and neurons in each layer. </font>"],"metadata":{"id":"RA6LY--v70is"}},{"cell_type":"code","source":["# Train the GNN\n","\n","# Validate and test on the respective datasets"],"metadata":{"id":"WyLP3i5x720Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color='blue'> Now use the model to generate embeddings on the entire dataset </font>"],"metadata":{"id":"6R4maP1n9ixo"}},{"cell_type":"code","source":["# Put the model in evaluation mode\n","\n","# Encode the data to obtain the final hidden layer representations"],"metadata":{"id":"aF-4FreCe1c2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color='blue'> Now try out various clustering algorithms on the node embeddings and find out the optimal number of clusters using elbow plot.\n","Calculate various metrics such as silhouette score, Calinski-Harabasz index, and Davies-Bouldin index for each cluster size.\n","Also create plots for metrics used against the number of clusters.\n","</font>"],"metadata":{"id":"eOiVM92W-MbE"}},{"cell_type":"code","source":["# Perform clustering using various algorithms on the node embeddings obtained from the GNN\n","\n","# Evaluate clustering performance"],"metadata":{"id":"7beJes3Oqfz1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Elbow plot to find out optimal number of clusters"],"metadata":{"id":"1672ytCnBbKa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot metrics vs number of clusters"],"metadata":{"id":"n1aWlrVh1ww4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Summary"],"metadata":{"id":"ek_KZFYVJT1i"}},{"cell_type":"markdown","source":["<font color='blue'> Summarize the steps taken and your observations in comparison to the manual featuring engineering performed in Mini ML Project on Graph ML.</font>\n"],"metadata":{"id":"31BwlIgqKNWV"}},{"cell_type":"markdown","source":["< Not adding any answer here, since the observations and steps will be subjective to Mini ML Project done by each learner>"],"metadata":{"id":"9V-vCeGFKUqp"}},{"cell_type":"markdown","source":["\n","<font color='blue'> Summarize the steps taken and your observations in comparison to the feature extraction done using AutoEncoders for downstream classification task.</font>"],"metadata":{"id":"8RytNhrXNEyA"}},{"cell_type":"markdown","source":["< Not adding any answer here, since the observations and steps will be subjective to AutoEncoder assignment done by each learner>"],"metadata":{"id":"DKtUKtFjNNbl"}},{"cell_type":"code","source":[],"metadata":{"id":"smC6nG5VNT0I"},"execution_count":null,"outputs":[]}]}